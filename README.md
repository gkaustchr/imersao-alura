# Projeto: Detecção de Conteúdo Sensível em Imagens
Este é um projeto que permite importar imagens do seu dispositivo, convertê-las e enviá-las para o AI Studio. Lá, as imagens são processadas para identificar se contêm conteúdo sensível. Se for detectado conteúdo sensível, a imagem não é mostrada. Caso contrário, são exibidos os itens identificados na imagem.

## Este projeto utiliza apenas HTML5, JavaScript, CSS e AI Studio.
[imersão-alura](https://www.google.com)

Este projeto é uma ótima opção para criar redes onde os usuários podem fazer upload de fotos, garantindo que apenas imagens apropriadas sejam carregadas.

### Funcionalidades
- Importa imagens do dispositivo do usuário.
- Converte e envia as imagens para o AI Studio para processamento.
- Identifica se a imagem contém conteúdo sensível.
- Mostra os itens identificados na imagem, caso não haja conteúdo sensível.
- Permite selecionar prompts específicos, como identificar conteúdo político.

### Como Usar
- Clone este repositório para sua máquina local.
- Execute o aplicativo em seu ambiente de desenvolvimento.
- Importe uma imagem do seu dispositivo.
- Aguarde o processamento da imagem pelo AI Studio.
- Verifique se a imagem contém conteúdo sensível.
- Visualize os itens identificados na imagem, se não houver conteúdo sensível.

### Dependências
- Biblioteca JavaScript para manipulação de imagens (por exemplo: fabric.js).
- Conexão com o AI Studio para processamento de imagem.

### Contribuição
- Contribuições são bem-vindas! Sinta-se à vontade para enviar pull requests ou abrir issues para relatar problemas ou sugerir melhorias.
  
![image](https://github.com/gkaustchr/imersao-alura/assets/21264174/db6c41a5-953b-4ce7-bf85-8b90e522ba2a)

![image](https://github.com/gkaustchr/imersao-alura/assets/21264174/735cc7e7-61c6-406b-a519-48131a9ffb60)

